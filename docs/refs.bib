
@article{polson_bayesian_2013,
	title = {Bayesian {Inference} for {Logistic} {Models} {Using} {Pólya}–{Gamma} {Latent} {Variables}},
	volume = {108},
	issn = {0162-1459},
	url = {http://dx.doi.org/10.1080/01621459.2013.829001},
	doi = {10.1080/01621459.2013.829001},
	abstract = {We propose a new data-augmentation strategy for fully Bayesian inference in models with binomial likelihoods. The approach appeals to a new class of Pólya–Gamma distributions, which are constructed in detail. A variety of examples are presented to show the versatility of the method, including logistic regression, negative binomial regression, nonlinear mixed-effect models, and spatial models for count data. In each case, our data-augmentation strategy leads to simple, effective methods for posterior inference that (1) circumvent the need for analytic approximations, numerical integration, or Metropolis–Hastings; and (2) outperform other known data-augmentation strategies, both in ease of use and in computational efficiency. All methods, including an efficient sampler for the Pólya–Gamma distribution, are implemented in the R package BayesLogit. Supplementary materials for this article are available online.},
	number = {504},
	urldate = {2016-09-15},
	journal = {Journal of the American Statistical Association},
	author = {Polson, Nicholas G. and Scott, James G. and Windle, Jesse},
	month = dec,
	year = {2013},
	pages = {1339--1349},
	file = {BayesianInferenceLogRegModelsPolyaGammaLatentVars.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/VDK8S2H4/BayesianInferenceLogRegModelsPolyaGammaLatentVars.pdf:application/pdf;Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/PDKP9JFH/Polson et al. - 2013 - Bayesian Inference for Logistic Models Using Pólya.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/HWBHFG72/01621459.2013.html:text/html;techsuppR1.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/SVUQ2BMZ/techsuppR1.pdf:application/pdf}
}

@article{casella_empirical_2001,
	title = {Empirical {Bayes} {Gibbs} sampling},
	volume = {2},
	number = {4},
	journal = {Biostatistics},
	author = {Casella, George},
	year = {2001},
	pages = {485--500},
	file = {Biostat-2001-Casella-485-500.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/38IRWHCP/Biostat-2001-Casella-485-500.pdf:application/pdf}
}

@article{kyung_penalized_2010,
	title = {Penalized regression, standard errors, and {Bayesian} lassos},
	volume = {5},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1340218343},
	doi = {10.1214/10-BA607},
	abstract = {Penalized regression methods for simultaneous variable selection and coefficient estimation, especially those based on the lasso of Tibshirani (1996), have received a great deal of attention in recent years, mostly through frequentist models. Properties such as consistency have been studied, and are achieved by different lasso variations. Here we look at a fully Bayesian formulation of the problem, which is flexible enough to encompass most versions of the lasso that have been previously considered. The advantages of the hierarchical Bayesian formulations are many. In addition to the usual ease-of-interpretation of hierarchical models, the Bayesian formulation produces valid standard errors (which can be problematic for the frequentist lasso), and is based on a geometrically ergodic Markov chain. We compare the performance of the Bayesian lassos to their frequentist counterparts using simulations, data sets that previous lasso papers have used, and a difficult modeling problem for predicting the collapse of governments around the world. In terms of prediction mean squared error, the Bayesian lasso performance is similar to and, in some cases, better than, the frequentist lasso.},
	language = {EN},
	number = {2},
	urldate = {2017-10-18},
	journal = {Bayesian Anal.},
	author = {Kyung, Minjung and Gill, Jeff and Ghosh, Malay and Casella, George},
	month = jun,
	year = {2010},
	mrnumber = {MR2719657},
	zmnumber = {1330.62289},
	keywords = {Geometric Ergodicity, Gibbs sampling, Hierarchical Models, Variable selection},
	pages = {369--411},
	file = {euclid.ba.1340218343.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/UZ7R4H27/euclid.ba.1340218343.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/8TGZTMSB/1340218343.html:text/html}
}

@article{cowen_network_2017,
	title = {Network propagation: a universal amplifier of genetic associations},
	volume = {18},
	copyright = {2017 Nature Publishing Group},
	issn = {1471-0064},
	shorttitle = {Network propagation},
	url = {https://www.nature.com/articles/nrg.2017.38},
	doi = {10.1038/nrg.2017.38},
	abstract = {{\textless}p{\textgreater}Network propagation is based on the principle that genes underlying similar phenotypes are more likely to interact with each other. It is proving to be a powerful approach for extracting biological information from molecular networks that is relevant to human disease.{\textless}/p{\textgreater}},
	language = {en},
	number = {9},
	urldate = {2017-11-21},
	journal = {Nature Reviews Genetics},
	author = {Cowen, Lenore and Ideker, Trey and Raphael, Benjamin J. and Sharan, Roded},
	month = jun,
	year = {2017},
	pages = {nrg.2017.38},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/GT4QBV8Z/Cowen et al. - 2017 - Network propagation a universal amplifier of gene.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/8R5XU3DR/nrg.2017.html:text/html}
}

@article{van_wieringen_ridge_2016,
	title = {Ridge estimation of inverse covariance matrices from high-dimensional data},
	volume = {103},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947316301141},
	doi = {10.1016/j.csda.2016.05.012},
	abstract = {The ridge estimation of the precision matrix is investigated in the setting where the number of variables is large relative to the sample size. First, two archetypal ridge estimators are reviewed and it is noted that their penalties do not coincide with common quadratic ridge penalties. Subsequently, starting from a proper ℓ2-penalty, analytic expressions are derived for two alternative ridge estimators of the precision matrix. The alternative estimators are compared to the archetypes with regard to eigenvalue shrinkage and risk. The alternatives are also compared to the graphical lasso within the context of graphical modeling. The comparisons may give reason to prefer the proposed alternative estimators.},
	number = {Supplement C},
	urldate = {2017-11-21},
	journal = {Computational Statistics \& Data Analysis},
	author = {van Wieringen, Wessel N. and Peeters, Carel F. W.},
	month = nov,
	year = {2016},
	keywords = {-penalization, Graphical modeling, High-dimensional precision matrix estimation, Multivariate normal, Precision matrix},
	pages = {284--303},
	file = {ScienceDirect Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/8SFEHKF6/van Wieringen and Peeters - 2016 - Ridge estimation of inverse covariance matrices fr.pdf:application/pdf;ScienceDirect Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/683EC9SW/S0167947316301141.html:text/html}
}

@article{van_wieringen_mean_2017,
	title = {On the mean squared error of the ridge estimator of the covariance and precision matrix},
	volume = {123},
	issn = {0167-7152},
	url = {http://www.sciencedirect.com/science/article/pii/S0167715216302863},
	doi = {10.1016/j.spl.2016.12.002},
	abstract = {For a suitably chosen ridge penalty parameter, the ridge regression estimator uniformly dominates the maximum likelihood regression estimator in terms of the mean squared error. Analogous results for the ridge maximum likelihood estimators of covariance and precision matrix are presented.},
	number = {Supplement C},
	urldate = {2017-11-21},
	journal = {Statistics \& Probability Letters},
	author = {van Wieringen, Wessel N.},
	month = apr,
	year = {2017},
	keywords = {-penalization, Inverse covariance matrix, Multivariate normal},
	pages = {88--92},
	file = {ScienceDirect Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/AWVH8CGE/van Wieringen - 2017 - On the mean squared error of the ridge estimator o.pdf:application/pdf;ScienceDirect Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/DC9TJ73X/S0167715216302863.html:text/html}
}

@article{peeters_spectral_2016,
	title = {The {Spectral} {Condition} {Number} {Plot} for {Regularization} {Parameter} {Determination}},
	url = {http://arxiv.org/abs/1608.04123},
	abstract = {Many modern statistical applications ask for the estimation of a covariance (or precision) matrix in settings where the number of variables is larger than the number of observations. There exists a broad class of ridge-type estimators that employs regularization to cope with the subsequent singularity of the sample covariance matrix. These estimators depend on a penalty parameter and choosing its value can be hard, in terms of being computationally unfeasible or tenable only for a restricted set of ridge-type estimators. Here we introduce a simple graphical tool, the spectral condition number plot, for informed heuristic penalty parameter selection. The proposed tool is computationally friendly and can be employed for the full class of ridge-type covariance (precision) estimators.},
	urldate = {2017-11-21},
	journal = {arXiv:1608.04123 [stat]},
	author = {Peeters, Carel F. W. and van de Wiel, Mark A. and van Wieringen, Wessel N.},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.04123},
	keywords = {Statistics - Computation, Statistics - Machine Learning},
	file = {arXiv\:1608.04123 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/GSP4R94B/Peeters et al. - 2016 - The Spectral Condition Number Plot for Regularizat.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6JHIS8RD/1608.html:text/html}
}

@article{belilovsky_testing_2015,
	title = {Testing for {Differences} in {Gaussian} {Graphical} {Models}: {Applications} to {Brain} {Connectivity}},
	shorttitle = {Testing for {Differences} in {Gaussian} {Graphical} {Models}},
	url = {http://arxiv.org/abs/1512.08643},
	abstract = {Functional brain networks are well described and estimated from data with Gaussian Graphical Models (GGMs), e.g. using sparse inverse covariance estimators. Comparing functional connectivity of subjects in two populations calls for comparing these estimated GGMs. Our goal is to identify differences in GGMs known to have similar structure. We characterize the uncertainty of differences with confidence intervals obtained using a parametric distribution on parameters of a sparse estimator. Sparse penalties enable statistical guarantees and interpretable models even in high-dimensional and low-sample settings. Characterizing the distributions of sparse models is inherently challenging as the penalties produce a biased estimator. Recent work invokes the sparsity assumptions to effectively remove the bias from a sparse estimator such as the lasso. These distributions can be used to give confidence intervals on edges in GGMs, and by extension their differences. However, in the case of comparing GGMs, these estimators do not make use of any assumed joint structure among the GGMs. Inspired by priors from brain functional connectivity we derive the distribution of parameter differences under a joint penalty when parameters are known to be sparse in the difference. This leads us to introduce the debiased multi-task fused lasso, whose distribution can be characterized in an efficient manner. We then show how the debiased lasso and multi-task fused lasso can be used to obtain confidence intervals on edge differences in GGMs. We validate the techniques proposed on a set of synthetic examples as well as neuro-imaging dataset created for the study of autism.},
	urldate = {2017-11-21},
	journal = {arXiv:1512.08643 [stat]},
	author = {Belilovsky, Eugene and Varoquaux, Gaël and Blaschko, Matthew B.},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.08643},
	keywords = {Statistics - Machine Learning},
	file = {arXiv\:1512.08643 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/W5AMXAEC/Belilovsky et al. - 2015 - Testing for Differences in Gaussian Graphical Mode.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6CSA7F5Z/1512.html:text/html}
}

@article{van_penalized_2014,
	title = {Penalized differential pathway analysis of integrative oncogenomics studies},
	volume = {13},
	issn = {1544-6115},
	url = {https://www.degruyter.com/view/j/sagmb.2014.13.issue-2/sagmb-2013-0020/sagmb-2013-0020.xml},
	doi = {10.1515/sagmb-2013-0020},
	abstract = {Through integration of genomic data from multiple sources, we may obtain a more accurate and complete picture of the molecular mechanisms underlying tumorigenesis. We discuss the integration of DNA copy number and mRNA gene expression data from an observational integrative genomics study involving cancer patients. The two molecular levels involved are linked through the central dogma of molecular biology. DNA copy number aberrations abound in the cancer cell. Here we investigate how these aberrations affect gene expression levels within a pathway using observational integrative genomics data of cancer patients. In particular, we aim to identify differential edges between regulatory networks of two groups involving these molecular levels. Motivated by the rate equations, the regulatory mechanism between DNA copy number aberrations and gene expression levels within a pathway is modeled by a simultaneous-equations model, for the one- and two-group case. The latter facilitates the identification of differential interactions between the two groups. Model parameters are estimated by penalized least squares using the lasso (L1) penalty to obtain a sparse pathway topology. Simulations show that the inclusion of DNA copy number data benefits the discovery of gene-gene interactions. In addition, the simulations reveal that cis-effects tend to be over-estimated in a univariate (single gene) analysis. In the application to real data from integrative oncogenomic studies we show that inclusion of prior information on the regulatory network architecture benefits the reproducibility of all edges. Furthermore, analyses of the TP53 and TGFb signaling pathways between ER+ and ER- samples from an integrative genomics breast cancer study identify reproducible differential regulatory patterns that corroborate with existing literature.},
	number = {2},
	urldate = {2017-11-21},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {van, Wieringen Wessel N. and van, de Wiel Mark A.},
	year = {2014},
	keywords = {cancer, data integration, penalized estimation, simultaneous-equations model (SEM)},
	pages = {141--158},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/8X4T9P49/van and van - 2014 - Penalized differential pathway analysis of integra.pdf:application/pdf}
}

@article{ma_estimation_2015,
	title = {Estimation and {Inference} for {High}-{Dimensional} {Gaussian} {Graphical} {Models} with {Structural} {Constraints}.},
	author = {Ma, Jing},
	year = {2015},
	file = {mjing_1.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/64JFADKA/mjing_1.pdf:application/pdf}
}

@article{latouche_goodness_2017,
	title = {Goodness of fit of logistic regression models for random graphs},
	issn = {1061-8600},
	url = {http://amstat.tandfonline.com/doi/abs/10.1080/10618600.2017.1349663},
	doi = {10.1080/10618600.2017.1349663},
	abstract = {The logistic regression model constitutes a natural and simple tool to understand how covariates (when available) contribute to explain the topology of a binary network. After estimating the logistic parameters, one of the main questions which arises in practice is to assess the goodness of fit of the corresponding model. To address this problem, we add a general term, related to the graphon function of W-graph models, to the logistic function. Such an extra term aims at characterizing the residual structure of the network, that is not explained by the covariates. We approximate this new generic logistic model using a class of models with blockwise constant residual structure. This framework allows to derive a Bayesian procedure from a model based selection context using goodness-of-fit criteria. All these criteria depend on marginal likelihood terms for which we do provide estimates relying on two series of variational approximations. Experiments on toy data are carried out to assess the inference procedure. Finally, six networks from social sciences and ecology are studied to illustrate the proposed methodology. Logistic regression is a natural and simple tool to understand how covariates contribute to explain the topology of a binary network. Once the model is fitted, the practitioner is interested in the goodness-of-fit of the regression in order to check if the covariates are sufficient to explain the whole topology of the network and, if they are not, to analyze the residual structure. To address this problem, we introduce a generic model that combines logistic regression with a network-oriented residual term. This residual term takes the form of the graphon function of a W-graph. Using a variational Bayes framework, we infer the residual graphon by averaging over a series of blockwise constant functions. This approach allows us to define a generic goodness-of-fit criterion, which corresponds to the posterior probability for the residual graphon to be constant. Experiments on toy data are carried out to assess the accuracy of the procedure. Several networks from social sciences and ecology are studied to illustrate the proposed methodology.},
	urldate = {2017-11-21},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Latouche, Pierre and Robin, Stéphane and Ouadah, Sarah},
	month = jul,
	year = {2017},
	pages = {0--0},
	file = {Goodness of fit of logistic regression models for random graphs.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/PH3CEXI6/Goodness of fit of logistic regression models for random graphs.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/RR3FDGTI/Latouche et al. - 2017 - Goodness of fit of logistic regression models for .html:text/html;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/98XVX9IS/Latouche et al. - 2017 - Goodness of fit of logistic regression models for .html:text/html;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/EV3PAWRK/Latouche et al. - 2017 - Goodness of fit of logistic regression models for .html:text/html;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/JTU4Z6M2/10618600.2017.html:text/html}
}

@article{bilgrau_targeted_2015,
	title = {Targeted {Fused} {Ridge} {Estimation} of {Inverse} {Covariance} {Matrices} from {Multiple} {High}-{Dimensional} {Data} {Classes}},
	url = {http://arxiv.org/abs/1509.07982},
	abstract = {We consider the problem of jointly estimating multiple precision matrices from (aggregated) high-dimensional data consisting of distinct classes. An \${\textbackslash}ell\_2\$-penalized maximum-likelihood approach is employed. The suggested approach is flexible and generic, incorporating several other \${\textbackslash}ell\_2\$-penalized estimators as special cases. In addition, the approach allows for the specification of target matrices through which prior knowledge may be incorporated and which can stabilize the estimation procedure in high-dimensional settings. The result is a targeted fused ridge estimator that is of use when the precision matrices of the constituent classes are believed to chiefly share the same structure while potentially differing in a number of locations of interest. It has many applications in (multi)factorial study designs. We focus on the graphical interpretation of precision matrices with the proposed estimator then serving as a basis for integrative or meta-analytic Gaussian graphical modeling. Situations are considered in which the classes are defined by data sets and/or (subtypes of) diseases. The performance of the proposed estimator in the graphical modeling setting is assessed through extensive simulation experiments. Its practical usability is illustrated by the differential network modeling of 11 large-scale diffuse large B-cell lymphoma gene expression data sets. The estimator and its related procedures are incorporated into the R-package rags2ridges.},
	urldate = {2017-11-22},
	journal = {arXiv:1509.07982 [q-bio, stat]},
	author = {Bilgrau, Anders Ellern and Peeters, Carel F. W. and Eriksen, Poul Svante and Bøgsted, Martin and van Wieringen, Wessel N.},
	month = sep,
	year = {2015},
	note = {arXiv: 1509.07982},
	keywords = {Quantitative Biology - Molecular Networks, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv\:1509.07982 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/P792TQ9P/Bilgrau et al. - 2015 - Targeted Fused Ridge Estimation of Inverse Covaria.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/URINWK3M/1509.html:text/html}
}

@article{ollerer_robust_2015,
	title = {Robust high-dimensional precision matrix estimation},
	url = {http://arxiv.org/abs/1501.01219},
	abstract = {The dependency structure of multivariate data can be analyzed using the covariance matrix \${\textbackslash}Sigma\$. In many fields the precision matrix \${\textbackslash}Sigma{\textasciicircum}\{-1\}\$ is even more informative. As the sample covariance estimator is singular in high-dimensions, it cannot be used to obtain a precision matrix estimator. A popular high-dimensional estimator is the graphical lasso, but it lacks robustness. We consider the high-dimensional independent contamination model. Here, even a small percentage of contaminated cells in the data matrix may lead to a high percentage of contaminated rows. Downweighting entire observations, which is done by traditional robust procedures, would then results in a loss of information. In this paper, we formally prove that replacing the sample covariance matrix in the graphical lasso with an elementwise robust covariance matrix leads to an elementwise robust, sparse precision matrix estimator computable in high-dimensions. Examples of such elementwise robust covariance estimators are given. The final precision matrix estimator is positive definite, has a high breakdown point under elementwise contamination and can be computed fast.},
	urldate = {2017-11-29},
	journal = {arXiv:1501.01219 [stat]},
	author = {Öllerer, Viktoria and Croux, Christophe},
	month = jan,
	year = {2015},
	note = {arXiv: 1501.01219},
	keywords = {Statistics - Methodology},
	file = {arXiv\:1501.01219 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/UPPB6BKZ/Öllerer and Croux - 2015 - Robust high-dimensional precision matrix estimatio.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/PTD9N8M2/1501.html:text/html}
}

@article{christley_incorporating_2009,
	title = {Incorporating {Existing} {Network} {Information} into {Gene} {Network} {Inference}},
	volume = {4},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0006799},
	doi = {10.1371/journal.pone.0006799},
	abstract = {One methodology that has met success to infer gene networks from gene expression data is based upon ordinary differential equations (ODE). However new types of data continue to be produced, so it is worthwhile to investigate how to integrate these new data types into the inference procedure. One such data is physical interactions between transcription factors and the genes they regulate as measured by ChIP-chip or ChIP-seq experiments. These interactions can be incorporated into the gene network inference procedure as a priori network information. In this article, we extend the ODE methodology into a general optimization framework that incorporates existing network information in combination with regularization parameters that encourage network sparsity. We provide theoretical results proving convergence of the estimator for our method and show the corresponding probabilistic interpretation also converges. We demonstrate our method on simulated network data and show that existing network information improves performance, overcomes the lack of observations, and performs well even when some of the existing network information is incorrect. We further apply our method to the core regulatory network of embryonic stem cells utilizing predicted interactions from two studies as existing network information. We show that including the prior network information constructs a more closely representative regulatory network versus when no information is provided.},
	language = {en},
	number = {8},
	urldate = {2018-03-14},
	journal = {PLOS ONE},
	author = {Christley, Scott and Nie, Qing and Xie, Xiaohui},
	month = aug,
	year = {2009},
	keywords = {Algorithms, Gene expression, Gene regulation, Gene regulatory networks, Genetic networks, Network analysis, Optimization, Transcription factors},
	pages = {e6799},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6RUGVGEC/Christley et al. - 2009 - Incorporating Existing Network Information into Ge.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/KMDJ5NJ2/article.pdf:application/pdf}
}

@article{binder_incorporating_2009,
	title = {Incorporating pathway information into boosting estimation of high-dimensional risk prediction models},
	volume = {10},
	issn = {1471-2105},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2647532/},
	doi = {10.1186/1471-2105-10-18},
	abstract = {Background
There are several techniques for fitting risk prediction models to high-dimensional data, arising from microarrays. However, the biological knowledge about relations between genes is only rarely taken into account. One recent approach incorporates pathway information, available, e.g., from the KEGG database, by augmenting the penalty term in Lasso estimation for continuous response models.

Results
As an alternative, we extend componentwise likelihood-based boosting techniques for incorporating pathway information into a larger number of model classes, such as generalized linear models and the Cox proportional hazards model for time-to-event data. In contrast to Lasso-like approaches, no further assumptions for explicitly specifying the penalty structure are needed, as pathway information is incorporated by adapting the penalties for single microarray features in the course of the boosting steps. This is shown to result in improved prediction performance when the coefficients of connected genes have opposite sign. The properties of the fitted models resulting from this approach are then investigated in two application examples with microarray survival data.

Conclusion
The proposed approach results not only in improved prediction performance but also in structurally different model fits. Incorporating pathway information in the suggested way is therefore seen to be beneficial in several ways.},
	urldate = {2018-04-09},
	journal = {BMC Bioinformatics},
	author = {Binder, Harald and Schumacher, Martin},
	month = jan,
	year = {2009},
	pmid = {19144132},
	pmcid = {PMC2647532},
	pages = {18},
	file = {PubMed Central Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/86PFZP78/Binder and Schumacher - 2009 - Incorporating pathway information into boosting es.pdf:application/pdf}
}

@article{li_network-constrained_2008,
	title = {Network-constrained regularization and variable selection for analysis of genomic data},
	volume = {24},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/24/9/1175/206444},
	doi = {10.1093/bioinformatics/btn081},
	abstract = {Motivation: Graphs or networks are common ways of depicting information. In biology in particular, many different biological processes are represented by graphs, such as regulatory networks or metabolic pathways. This kind of a priori information gathered over many years of biomedical research is a useful supplement to the standard numerical genomic data such as microarray gene-expression data. How to incorporate information encoded by the known biological networks or graphs into analysis of numerical data raises interesting statistical challenges. In this article, we introduce a network-constrained regularization procedure for linear regression analysis in order to incorporate the information from these graphs into an analysis of the numerical data, where the network is represented as a graph and its corresponding Laplacian matrix. We define a network-constrained penalty function that penalizes the L1-norm of the coefficients but encourages smoothness of the coefficients on the network.Results: Simulation studies indicated that the method is quite effective in identifying genes and subnetworks that are related to disease and has higher sensitivity than the commonly used procedures that do not use the pathway structure information. Application to one glioblastoma microarray gene-expression dataset identified several subnetworks on several of the Kyoto Encyclopedia of Genes and Genomes (KEGG) transcriptional pathways that are related to survival from glioblastoma, many of which were supported by published literatures.Conclusions: The proposed network-constrained regularization procedure efficiently utilizes the known pathway structures in identifying the relevant genes and the subnetworks that might be related to phenotype in a general regression framework. As more biological networks are identified and documented in databases, the proposed method should find more applications in identifying the subnetworks that are related to diseases and other biological processes.Contact:hongzhe@mail.med.upenn.edu},
	language = {en},
	number = {9},
	urldate = {2018-04-09},
	journal = {Bioinformatics},
	author = {Li, Caiyan and Li, Hongzhe},
	month = may,
	year = {2008},
	pages = {1175--1182},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/Z9796N48/Li and Li - 2008 - Network-constrained regularization and variable se.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/NG2MJ8P8/206444.html:text/html}
}

@article{wei_nonparametric_2007,
	title = {Nonparametric pathway-based regression models for analysis of genomic data},
	volume = {8},
	issn = {1465-4644},
	url = {https://academic.oup.com/biostatistics/article/8/2/265/230606},
	doi = {10.1093/biostatistics/kxl007},
	abstract = {High-throughout genomic data provide an opportunity for identifying pathways and genes that are related to various clinical phenotypes. Besides these genomic data, another valuable source of data is the biological knowledge about genes and pathways that might be related to the phenotypes of many complex diseases. Databases of such knowledge are often called the metadata. In microarray data analysis, such metadata are currently explored in post hoc ways by gene set enrichment analysis but have hardly been utilized in the modeling step. We propose to develop and evaluate a pathway-based gradient descent boosting procedure for nonparametric pathways-based regression (NPR) analysis to efficiently integrate genomic data and metadata. Such NPR models consider multiple pathways simultaneously and allow complex interactions among genes within the pathways and can be applied to identify pathways and genes that are related to variations of the phenotypes. These methods also provide an alternative to mediating the problem of a large number of potential interactions by limiting analysis to biologically plausible interactions between genes in related pathways. Our simulation studies indicate that the proposed boosting procedure can indeed identify relevant pathways. Application to a gene expression data set on breast cancer distant metastasis identified that Wnt, apoptosis, and cell cycle-regulated pathways are more likely related to the risk of distant metastasis among lymph-node-negative breast cancer patients. Results from analysis of other two breast cancer gene expression data sets indicate that the pathways of Metalloendopeptidases (MMPs) and MMP inhibitors, as well as cell proliferation, cell growth, and maintenance are important to breast cancer relapse and survival. We also observed that by incorporating the pathway information, we achieved better prediction for cancer recurrence.},
	language = {en},
	number = {2},
	urldate = {2018-04-16},
	journal = {Biostatistics},
	author = {Wei, Zhi and Li, Hongzhe},
	month = apr,
	year = {2007},
	pages = {265--284},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/B264N3X3/Wei and Li - 2007 - Nonparametric pathway-based regression models for .pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/82RXSEMG/230606.html:text/html}
}

@article{donnet_empirical_2010,
	title = {An empirical {Bayes} procedure for the selection of {Gaussian} graphical models},
	url = {http://arxiv.org/abs/1003.5851},
	abstract = {A new methodology for model determination in decomposable graphical Gaussian models is developed. The Bayesian paradigm is used and, for each given graph, a hyper inverse Wishart prior distribution on the covariance matrix is considered. This prior distribution depends on hyper-parameters. It is well-known that the models's posterior distribution is sensitive to the specification of these hyper-parameters and no completely satisfactory method is registered. In order to avoid this problem, we suggest adopting an empirical Bayes strategy, that is a strategy for which the values of the hyper-parameters are determined using the data. Typically, the hyper-parameters are fixed to their maximum likelihood estimations. In order to calculate these maximum likelihood estimations, we suggest a Markov chain Monte Carlo version of the Stochastic Approximation EM algorithm. Moreover, we introduce a new sampling scheme in the space of graphs that improves the add and delete proposal of Armstrong et al. (2009). We illustrate the efficiency of this new scheme on simulated and real datasets.},
	urldate = {2018-04-17},
	journal = {arXiv:1003.5851 [stat]},
	author = {Donnet, Sophie and Marin, Jean-Michel},
	month = mar,
	year = {2010},
	note = {arXiv: 1003.5851},
	keywords = {Statistics - Computation},
	file = {arXiv\:1003.5851 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/7V4BVDQZ/Donnet and Marin - 2010 - An empirical Bayes procedure for the selection of .pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/2KH325H8/1003.html:text/html}
}

@article{marlin_group_2012,
	title = {Group {Sparse} {Priors} for {Covariance} {Estimation}},
	url = {http://arxiv.org/abs/1205.2626},
	abstract = {Recently it has become popular to learn sparse Gaussian graphical models (GGMs) by imposing l1 or group l1,2 penalties on the elements of the precision matrix. Thispenalized likelihood approach results in a tractable convex optimization problem. In this paper, we reinterpret these results as performing MAP estimation under a novel prior which we call the group l1 and l1,2 positivedefinite matrix distributions. This enables us to build a hierarchical model in which the l1 regularization terms vary depending on which group the entries are assigned to, which in turn allows us to learn block structured sparse GGMs with unknown group assignments. Exact inference in this hierarchical model is intractable, due to the need to compute the normalization constant of these matrix distributions. However, we derive upper bounds on the partition functions, which lets us use fast variational inference (optimizing a lower bound on the joint posterior). We show that on two real world data sets (motion capture and financial data), our method which infers the block structure outperforms a method that uses a fixed block structure, which in turn outperforms baseline methods that ignore block structure.},
	urldate = {2018-04-17},
	journal = {arXiv:1205.2626 [cs, stat]},
	author = {Marlin, Benjamin and Schmidt, Mark and Murphy, Kevin},
	month = may,
	year = {2012},
	note = {arXiv: 1205.2626},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1205.2626 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/GGTFADIB/Marlin et al. - 2012 - Group Sparse Priors for Covariance Estimation.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/QEFA2VEK/1205.html:text/html}
}

@book{marlin_sparse_nodate,
	title = {Sparse {Gaussian} {Graphical} {Models} with {Unknown} {Block} {Structure}},
	abstract = {Recent work has shown that one can learn the structure of Gaussian Graphical Models by imposing an L1 penalty on the precision matrix, and then using efficient convex optimization methods to find the penalized maximum likelihood estimate. This is similar to performing MAP estimation with a prior that prefers sparse graphs. In this paper, we use the stochastic block model as a prior. This prefer graphs that are blockwise sparse, but unlike previous work, it does not require that the blocks or groups be specified a priori. The resulting problem is no longer convex, but we devise an efficient variational Bayes algorithm to solve it. We show that our method has better test set likelihood on two different datasets (motion capture and gene expression) compared to independent L1, and can match the performance of group L1 using manually created groups. 1.},
	author = {Marlin, Benjamin M. and Murphy, Kevin P.},
	file = {Citeseer - Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/EQATAPKD/Marlin and Murphy - Sparse Gaussian Graphical Models with Unknown Bloc.pdf:application/pdf;Citeseer - Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/86R6XGCP/summary.html:text/html}
}

@article{wang_bayesian_2012,
	title = {Bayesian {Graphical} {Lasso} {Models} and {Efficient} {Posterior} {Computation}},
	volume = {7},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1354024465},
	doi = {10.1214/12-BA729},
	abstract = {Recently, the graphical lasso procedure has become popular in estimating Gaussian graphical models. In this paper, we introduce a fully Bayesian treatment of graphical lasso models. We first investigate the graphical lasso prior that has been relatively unexplored. Using data augmentation, we develop a simple but highly efficient block Gibbs sampler for simulating covariance matrices. We then generalize the Bayesian graphical lasso to the Bayesian adaptive graphical lasso. Finally, we illustrate and compare the results from our approach to those obtained using the standard graphical lasso procedures for real and simulated data. In terms of both covariance matrix estimation and graphical structure learning, the Bayesian adaptive graphical lasso appears to be the top overall performer among a range of frequentist and Bayesian methods.},
	language = {EN},
	number = {4},
	urldate = {2018-04-17},
	journal = {Bayesian Anal.},
	author = {Wang, Hao},
	month = dec,
	year = {2012},
	mrnumber = {MR3000017},
	zmnumber = {1330.62041},
	keywords = {Adaptive graphical lasso, Block Gibbs sampler, Constrained parameter spaces, Covariance matrix estimation, Double-exponential distribution, Graphical lasso},
	pages = {867--886},
	file = {euclid.ba.1354024465.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6U8G8UVN/euclid.ba.1354024465.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/WTTR7ZZ3/1354024465.html:text/html}
}

@article{sun_bayesian_2010,
	title = {A {Bayesian} {Approach} for {Graph}-constrained {Estimation} for {High}-dimensional {Regression}},
	volume = {1},
	issn = {0976-6774},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4373540/},
	abstract = {Many different biological processes are represented by network graphs such as regulatory networks, metabolic pathways, and protein-protein interaction networks. Since genes that are linked on the networks usually have biologically similar functions, the linked genes form molecular modules to affect the clinical phenotypes/outcomes. Similarly, in large-scale genetic association studies, many SNPs are in high linkage disequilibrium (LD), which can also be summarized as a LD graph. In order to incorporate the graph information into regression analysis with high dimensional genomic data as predictors, we introduce a Bayesian approach for graph-constrained estimation (Bayesian GRACE) and regularization, which controls the amount of regularization for sparsity and smoothness of the regression coefficients. The Bayesian estimation with their posterior distributions can provide credible intervals for the estimates of the regression coefficients along with standard errors. The deviance information criterion (DIC) is applied for model assessment and tuning parameter selection. The performance of the proposed Bayesian approach is evaluated through simulation studies and is compared with Bayesian Lasso and Bayesian Elastic-net procedures. We demonstrate our method in an analysis of data from a case-control genome-wide association study of neuroblastoma using a weighted LD graph.},
	number = {2},
	urldate = {2018-04-19},
	journal = {Int J Syst Synth Biol},
	author = {Sun, Hokeun and Li, Hongzhe},
	year = {2010},
	pmid = {25821387},
	pmcid = {PMC4373540},
	pages = {255--272},
	file = {PubMed Central Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/HFW494KV/Sun and Li - 2010 - A Bayesian Approach for Graph-constrained Estimati.pdf:application/pdf}
}

@article{li_variable_2010,
	title = {Variable selection and regression analysis for graph-structured covariates with an application to genomics},
	volume = {4},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/euclid.aoas/1287409383},
	doi = {10.1214/10-AOAS332},
	abstract = {Graphs and networks are common ways of depicting biological information. In biology, many different biological processes are represented by graphs, such as regulatory networks, metabolic pathways and protein–protein interaction networks. This kind of a priori use of graphs is a useful supplement to the standard numerical data such as microarray gene expression data. In this paper we consider the problem of regression analysis and variable selection when the covariates are linked on a graph. We study a graph-constrained regularization procedure and its theoretical properties for regression analysis to take into account the neighborhood information of the variables measured on a graph. This procedure involves a smoothness penalty on the coefficients that is defined as a quadratic form of the Laplacian matrix associated with the graph. We establish estimation and model selection consistency results and provide estimation bounds for both fixed and diverging numbers of parameters in regression models. We demonstrate by simulations and a real data set that the proposed procedure can lead to better variable selection and prediction than existing methods that ignore the graph information associated with the covariates.},
	language = {EN},
	number = {3},
	urldate = {2018-04-19},
	journal = {Ann. Appl. Stat.},
	author = {Li, Caiyan and Li, Hongzhe},
	month = sep,
	year = {2010},
	mrnumber = {MR2758338},
	zmnumber = {1202.62157},
	keywords = {High-dimensional data, Laplacian matrix, network, Regularization, sign consistency},
	pages = {1498--1516},
	file = {euclid.aoas.1287409383.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/BZ76QZX8/euclid.aoas.1287409383.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/CQIW7Z3B/1287409383.html:text/html}
}

@article{shimamura_bayesian_2016,
	title = {Bayesian generalized fused lasso modeling via {NEG} distribution},
	url = {http://arxiv.org/abs/1602.04910},
	abstract = {The fused lasso penalizes a loss function by the \$L\_1\$ norm for both the regression coefficients and their successive differences to encourage sparsity of both. In this paper, we propose a Bayesian generalized fused lasso modeling based on a normal-exponential-gamma (NEG) prior distribution. The NEG prior is assumed into the difference of successive regression coefficients. The proposed method enables us to construct a more versatile sparse model than the ordinary fused lasso by using a flexible regularization term. We also propose a sparse fused algorithm to produce exact sparse solutions. Simulation studies and real data analyses show that the proposed method has superior performance to the ordinary fused lasso.},
	urldate = {2018-04-25},
	journal = {arXiv:1602.04910 [stat]},
	author = {Shimamura, Kaito and Ueki, Masao and Kawano, Shuichi and Konishi, Sadanori},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.04910},
	keywords = {Primary 62F15, 62J07, Secondary 62J05, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv\:1602.04910 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/A7KPE4VV/Shimamura et al. - 2016 - Bayesian generalized fused lasso modeling via NEG .pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/53FCTAN9/1602.html:text/html}
}

@article{zhou_bayesian_2013,
	title = {Bayesian hierarchical graph-structured model for pathway analysis using gene expression data},
	volume = {12},
	issn = {1544-6115},
	url = {https://www.degruyter.com/view/j/sagmb.2013.12.issue-3/sagmb-2013-0011/sagmb-2013-0011.xml},
	doi = {10.1515/sagmb-2013-0011},
	abstract = {In genomic analysis, there is growing interest in network structures that represent biochemistry interactions. Graph structured or constrained inference takes advantage of a known relational structure among variables to introduce smoothness and reduce complexity in modeling, especially for high-dimensional genomic data. There has been a lot of interest in its application in model regularization and selection. However, prior knowledge on the graphical structure among the variables can be limited and partial. Empirical data may suggest variations and modifications to such a graph, which could lead to new and interesting biological findings. In this paper, we propose a Bayesian random graph-constrained model, rGrace, an extension from the Grace model, to combine a priori network information with empirical evidence, for applications such as pathway analysis. Using both simulations and real data examples, we show that the new method, while leading to improved predictive performance, can identify discrepancy between data and a prior known graph structure and suggest modifications and updates.},
	number = {3},
	urldate = {2018-04-25},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {Zhou, Hui and Zheng, Tian},
	year = {2013},
	keywords = {Bayesian anslysis, Gene expression, Network analysis},
	pages = {393--412},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/X28D4PPN/Zhou and Zheng - 2013 - Bayesian hierarchical graph-structured model for p.pdf:application/pdf}
}

@article{peterson_joint_2016,
	title = {Joint {Bayesian} variable and graph selection for regression models with network-structured predictors},
	volume = {35},
	copyright = {Copyright © 2015 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6792},
	doi = {10.1002/sim.6792},
	abstract = {In this work, we develop a Bayesian approach to perform selection of predictors that are linked within a network. We achieve this by combining a sparse regression model relating the predictors to a response variable with a graphical model describing conditional dependencies among the predictors. The proposed method is well-suited for genomic applications because it allows the identification of pathways of functionally related genes or proteins that impact an outcome of interest. In contrast to previous approaches for network-guided variable selection, we infer the network among predictors using a Gaussian graphical model and do not assume that network information is available a priori. We demonstrate that our method outperforms existing methods in identifying network-structured predictors in simulation settings and illustrate our proposed model with an application to inference of proteins relevant to glioblastoma survival. Copyright © 2015 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {7},
	urldate = {2018-04-30},
	journal = {Statistics in Medicine},
	author = {Peterson, Christine B. and Stingo, Francesco C. and Vannucci, Marina},
	month = mar,
	year = {2016},
	keywords = {Bayesian variable selection, Gaussian graphical model, linear model, protein network},
	pages = {1017--1031},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/7I7ADV6M/Peterson et al. - 2016 - Joint Bayesian variable and graph selection for re.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/XBQTMZXW/sim.html:text/html}
}

@article{pan_incorporating_2010,
	title = {Incorporating {Predictor} {Network} in {Penalized} {Regression} with {Application} to {Microarray} {Data}},
	volume = {66},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/40663240},
	abstract = {We consider penalized linear regression, especially for "large p, small n" problems, for which the relationships among predictors are described a priori by a network. A class of motivating examples includes modeling a phenotype through gene expression profiles while accounting for coordinated functioning of genes in the form of biological pathways or networks. To incorporate the prior knowledge of the similar effect sizes of neighboring predictors in a network, we propose a grouped penalty based on the L $_{\textrm{γ}}$ -norm that smoothes the regression coefficients of the predictors over the network. The main feature of the proposed method is its ability to automatically realize grouped variable selection and exploit grouping effects. We also discuss effects of the choices of the γ and some weights inside the L $_{\textrm{γ}}$ -norm. Simulation studies demonstrate the superior finite-sample performance of the proposed method as compared to Lasso, elastic net, and a recently proposed network-based method. The new method performs best in variable selection across all simulation set-ups considered. For illustration, the method is applied to a microarray dataset to predict survival times for some glioblastoma patients using a gene expression dataset and a gene network compiled from some Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways.},
	number = {2},
	urldate = {2018-04-30},
	journal = {Biometrics},
	author = {Pan, Wei and Xie, Benhuai and Shen, Xiaotong},
	year = {2010},
	pages = {474--484},
	file = {JSTOR Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/AAV9D5ME/Pan et al. - 2010 - Incorporating Predictor Network in Penalized Regre.pdf:application/pdf}
}

@article{huang_sparse_2011,
	title = {{THE} {SPARSE} {LAPLACIAN} {SHRINKAGE} {ESTIMATOR} {FOR} {HIGH}-{DIMENSIONAL} {REGRESSION}},
	volume = {39},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/23033591},
	abstract = {We propose a new penalized method for variable selection and estimation that explicitly incorporates the correlation patterns among predictors. This method is based on a combination of the minimax concave penalty and Laplacian quadratic associated with a graph as the penalty function. We call in the sparse Laplacian shrinkage (SLS) method. The SLS uses the minimax concave penalty for encouraging sparsity and Laplacian quadratic penalty for promoting smoothness among coefficients associated with the correlated predictors. The SLS has a generalized grouping property with respect to the graph represented by the Laplacian quadratic. We show that the SLS possesses an oracle property in the sense that it is selection consistent and equal to the oracle Laplacian shrinkage estimator with high probability. This result holds in sparse, high-dimensional settings with p » n under reasonable conditions. We derive a coordinate descent algorithm for computing the SLS estimates. Simulation studies are conducted to evaluate the performance of the SLS method and a real data example is used to illustrate its application.},
	number = {4},
	urldate = {2018-04-30},
	journal = {The Annals of Statistics},
	author = {Huang, Jian and Ma, Shuangge and Li, Hongzhe and Zhang, Cun-Hui},
	year = {2011},
	pages = {2021--2046},
	file = {JSTOR Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/R6R75N3Z/Huang et al. - 2011 - THE SPARSE LAPLACIAN SHRINKAGE ESTIMATOR FOR HIGH-.pdf:application/pdf}
}

@article{kim_network-based_2013,
	title = {Network-{Based} {Penalized} {Regression} {With} {Application} to {Genomic} {Data}},
	volume = {69},
	copyright = {© 2013, The International Biometric Society},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12035},
	doi = {10.1111/biom.12035},
	abstract = {Penalized regression approaches are attractive in dealing with high-dimensional data such as arising in high-throughput genomic studies. New methods have been introduced to utilize the network structure of predictors, for example, gene networks, to improve parameter estimation and variable selection. All the existing network-based penalized methods are based on an assumption that parameters, for example, regression coefficients, of neighboring nodes in a network are close in magnitude, which however may not hold. Here we propose a novel penalized regression method based on a weaker prior assumption that the parameters of neighboring nodes in a network are likely to be zero (or non-zero) at the same time, regardless of their specific magnitudes. We propose a novel non-convex penalty function to incorporate this prior, and an algorithm based on difference convex programming. We use simulated data and two breast cancer gene expression datasets to demonstrate the advantages of the proposed methods over some existing methods. Our proposed methods can be applied to more general problems for group variable selection.},
	language = {en},
	number = {3},
	urldate = {2018-04-30},
	journal = {Biometrics},
	author = {Kim, Sunkyung and Pan, Wei and Shen, Xiaotong},
	month = sep,
	year = {2013},
	keywords = {Gene expression, Networks analysis, Nonconvex minimization, Penalty, Truncated Lasso penalty},
	pages = {582--593},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/78DE9B9C/Kim et al. - 2013 - Network-Based Penalized Regression With Applicatio.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/2RNGHU39/biom.html:text/html}
}

@article{li_bayesian_2010,
	title = {Bayesian {Variable} {Selection} in {Structured} {High}-{Dimensional} {Covariate} {Spaces} {With} {Applications} in {Genomics}},
	volume = {105},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/jasa.2010.tm08177},
	doi = {10.1198/jasa.2010.tm08177},
	abstract = {We consider the problem of variable selection in regression modeling in high-dimensional spaces where there is known structure among the covariates. This is an unconventional variable selection problem for two reasons: (1) The dimension of the covariate space is comparable, and often much larger, than the number of subjects in the study, and (2) the covariate space is highly structured, and in some cases it is desirable to incorporate this structural information in to the model building process. We approach this problem through the Bayesian variable selection framework, where we assume that the covariates lie on an undirected graph and formulate an Ising prior on the model space for incorporating structural information. Certain computational and statistical problems arise that are unique to such high-dimensional, structured settings, the most interesting being the phenomenon of phase transitions. We propose theoretical and computational schemes to mitigate these problems. We illustrate our methods on two different graph structures: the linear chain and the regular graph of degree k. Finally, we use our methods to study a specific application in genomics: the modeling of transcription factor binding sites in DNA sequences.},
	number = {491},
	urldate = {2018-04-30},
	journal = {Journal of the American Statistical Association},
	author = {Li, Fan and Zhang, Nancy R.},
	month = sep,
	year = {2010},
	keywords = {Ising model, Markov chain Monte Carlo, Motif analysis, Phase transition, Undirected graph},
	pages = {1202--1214},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/DNRXD2FF/Li and Zhang - 2010 - Bayesian Variable Selection in Structured High-Dim.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6KUF9DPN/jasa.2010.html:text/html}
}

@article{stingo_incorporating_2011,
	title = {Incorporating biological information into linear models: {A} {Bayesian} approach to the selection of pathways and genes},
	volume = {5},
	issn = {1932-6157, 1941-7330},
	shorttitle = {Incorporating biological information into linear models},
	url = {https://projecteuclid.org/euclid.aoas/1318514292},
	doi = {10.1214/11-AOAS463},
	abstract = {The vast amount of biological knowledge accumulated over the years has allowed researchers to identify various biochemical interactions and define different families of pathways. There is an increased interest in identifying pathways and pathway elements involved in particular biological processes. Drug discovery efforts, for example, are focused on identifying biomarkers as well as pathways related to a disease. We propose a Bayesian model that addresses this question by incorporating information on pathways and gene networks in the analysis of DNA microarray data. Such information is used to define pathway summaries, specify prior distributions, and structure the MCMC moves to fit the model. We illustrate the method with an application to gene expression data with censored survival outcomes. In addition to identifying markers that would have been missed otherwise and improving prediction accuracy, the integration of existing biological knowledge into the analysis provides a better understanding of underlying molecular processes.},
	language = {EN},
	number = {3},
	urldate = {2018-04-30},
	journal = {Ann. Appl. Stat.},
	author = {Stingo, Francesco C. and Chen, Yian A. and Tadesse, Mahlet G. and Vannucci, Marina},
	month = sep,
	year = {2011},
	mrnumber = {MR2884929},
	zmnumber = {1228.62150},
	keywords = {Bayesian variable selection, Gene expression, Markov chain Monte Carlo, Markov random field prior, pathway selection},
	pages = {1978--2002},
	file = {euclid.aoas.1318514292.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6NSE4HQZ/euclid.aoas.1318514292.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/A5DP9TVM/1318514292.html:text/html}
}

@article{hill_integrating_2012,
	title = {Integrating biological knowledge into variable selection: an empirical {Bayes} approach with an application in cancer biology},
	volume = {13},
	issn = {1471-2105},
	shorttitle = {Integrating biological knowledge into variable selection},
	url = {https://doi.org/10.1186/1471-2105-13-94},
	doi = {10.1186/1471-2105-13-94},
	abstract = {An important question in the analysis of biochemical data is that of identifying subsets of molecular variables that may jointly influence a biological response. Statistical variable selection methods have been widely used for this purpose. In many settings, it may be important to incorporate ancillary biological information concerning the variables of interest. Pathway and network maps are one example of a source of such information. However, although ancillary information is increasingly available, it is not always clear how it should be used nor how it should be weighted in relation to primary data.},
	urldate = {2018-04-30},
	journal = {BMC Bioinformatics},
	author = {Hill, Steven M. and Neve, Richard M. and Bayani, Nora and Kuo, Wen-Lin and Ziyad, Safiyyah and Spellman, Paul T. and Gray, Joe W. and Mukherjee, Sach},
	month = may,
	year = {2012},
	keywords = {Bayesian variable selection, Inclusion Probability, Lasso, Marginal Likelihood, Markov Random Field},
	pages = {94},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/KFZZXJ8Q/Hill et al. - 2012 - Integrating biological knowledge into variable sel.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/EJ9N4TKV/1471-2105-13-94.html:text/html}
}

@article{liu_bayesian_2014,
	title = {Bayesian {Regularization} via {Graph} {Laplacian}},
	volume = {9},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1401148316},
	doi = {10.1214/14-BA860},
	abstract = {Regularization plays a critical role in modern statistical research, especially in high-dimensional variable selection problems. Existing Bayesian methods usually assume independence between variables a priori. In this article, we propose a novel Bayesian approach, which explicitly models the dependence structure through a graph Laplacian matrix. We also generalize the graph Laplacian to allow both positively and negatively correlated variables. A prior distribution for the graph Laplacian is then proposed, which allows conjugacy and thereby greatly simplifies the computation. We show that the proposed Bayesian model leads to proper posterior distribution. Connection is made between our method and some existing regularization methods, such as Elastic Net, Lasso, Octagonal Shrinkage and Clustering Algorithm for Regression (OSCAR) and Ridge regression. An efficient Markov Chain Monte Carlo method based on parameter augmentation is developed for posterior computation. Finally, we demonstrate the method through several simulation studies and an application on a real data set involving key performance indicators of electronics companies.},
	language = {EN},
	number = {2},
	urldate = {2018-04-30},
	journal = {Bayesian Anal.},
	author = {Liu, Fei and Chakraborty, Sounak and Li, Fan and Liu, Yan and Lozano, Aurelie C.},
	month = jun,
	year = {2014},
	mrnumber = {MR3217003},
	zmnumber = {1327.62152},
	keywords = {Bayesian analysis, Elastic net, Grouping, Lasso, OSCAR, Regularization, Ridge regression, Variable selection},
	pages = {449--474},
	file = {euclid.ba.1401148316.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/AJJAWAGA/euclid.ba.1401148316.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/6ZX5D5E6/1401148316.html:text/html}
}

@article{dobra_variable_2009,
	title = {Variable selection and dependency networks for genomewide data},
	volume = {10},
	issn = {1465-4644},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2742495/},
	doi = {10.1093/biostatistics/kxp018},
	abstract = {We describe a new stochastic search algorithm for linear regression models called the bounded mode stochastic search (BMSS). We make use of BMSS to perform variable selection and classification as well as to construct sparse dependency networks. Furthermore, we show how to determine genetic networks from genomewide data that involve any combination of continuous and discrete variables. We illustrate our methodology with several real-world data sets.},
	number = {4},
	urldate = {2018-04-30},
	journal = {Biostatistics},
	author = {Dobra, Adrian},
	month = oct,
	year = {2009},
	pmid = {19520789},
	pmcid = {PMC2742495},
	pages = {621--639},
	file = {PubMed Central Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/DGPEK3CQ/Dobra - 2009 - Variable selection and dependency networks for gen.pdf:application/pdf}
}

@article{gelfand_proper_2003,
	title = {Proper multivariate conditional autoregressive models for spatial data analysis},
	volume = {4},
	issn = {1465-4644},
	url = {https://academic.oup.com/biostatistics/article/4/1/11/246085},
	doi = {10.1093/biostatistics/4.1.11},
	abstract = {In the past decade conditional autoregressive modelling specifications have found considerable application for the analysis of spatial data. Nearly all of this work is done in the univariate case and employs an improper specification. Our contribution here is to move to multivariate conditional autoregressive models and to provide rich, flexible classes which yield proper distributions. Our approach is to introduce spatial autoregression parameters. We first clarify what classes can be developed from the family of Mardia (1988) and contrast with recent work of Kim et al. (2000). We then present a novel parametric linear transformation which provides an extension with attractive interpretation. We propose to employ these models as specifications for second‐stage spatial effects in hierarchical models. Two applications are discussed; one for the two‐dimensional case modelling spatial patterns of child growth, the other for a four‐dimensional situation modelling spatial variation in HLA‐B allele frequencies. In each case, full Bayesian inference is carried out using Markov chain Monte Carlo simulation.},
	language = {en},
	number = {1},
	urldate = {2018-05-01},
	journal = {Biostatistics},
	author = {Gelfand, Alan E. and Vounatsou, Penelope},
	month = jan,
	year = {2003},
	pages = {11--15},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/H4UZPKAB/Gelfand and Vounatsou - 2003 - Proper multivariate conditional autoregressive mod.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/A36KJWST/246085.html:text/html}
}

@inproceedings{xin_efficient_2014,
	title = {Efficient {Generalized} {Fused} {Lasso} and its {Application} to the {Diagnosis} of {Alzheimer}'s {Disease}.},
	booktitle = {{AAAI}},
	author = {Xin, Bo and Kawahara, Yoshinobu and Wang, Yizhou and Gao, Wen},
	year = {2014},
	pages = {2163--2169},
	file = {8261-38583-1-PB.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/3ZUDHT45/8261-38583-1-PB.pdf:application/pdf}
}

@article{she_sparse_2010,
	title = {Sparse regression with exact clustering},
	volume = {4},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1286889184},
	doi = {10.1214/10-EJS578},
	abstract = {This paper studies a generic sparse regression problem with a customizable sparsity pattern matrix, motivated by, but not limited to, a supervised gene clustering problem in microarray data analysis. The clustered lasso method is proposed with the l1-type penalties imposed on both the coefficients and their pairwise differences. Somewhat surprisingly, it behaves differently than the lasso or the fused lasso – the exact clustering effect expected from the l1 penalization is rarely seen in applications. An asymptotic study is performed to investigate the power and limitations of the l1-penalty in sparse regression. We propose to combine data-augmentation and weights to improve the l1 technique. To address the computational issues in high dimensions, we successfully generalize a popular iterative algorithm both in practice and in theory and propose an ‘annealing’ algorithm applicable to generic sparse regressions (including the fused/clustered lasso). Some effective accelerating techniques are further investigated to boost the convergence. The accelerated annealing (AA) algorithm, involving only matrix multiplications and thresholdings, can handle a large design matrix as well as a large sparsity pattern matrix.},
	language = {EN},
	urldate = {2018-06-25},
	journal = {Electron. J. Statist.},
	author = {She, Yiyuan},
	year = {2010},
	mrnumber = {MR2727453},
	zmnumber = {1329.62327},
	keywords = {clustering, Lasso, Sparsity, Thresholding},
	pages = {1055--1096},
	file = {euclid.ejs.1286889184.pdf:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/9B37A5DI/euclid.ejs.1286889184.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/XN59836Q/1286889184.html:text/html}
}

@article{kanehisa_kegg:_2000,
	title = {{KEGG}: {Kyoto} {Encyclopedia} of {Genes} and {Genomes}},
	volume = {28},
	issn = {0305-1048},
	shorttitle = {{KEGG}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC102409/},
	abstract = {KEGG (Kyoto Encyclopedia of Genes and Genomes) is a knowledge base for systematic analysis of gene functions, linking genomic information with higher order functional information. The genomic information is stored in the GENES database, which is a collection of gene catalogs for all the completely sequenced genomes and some partial genomes with up-to-date annotation of gene functions. The higher order functional information is stored in the PATHWAY database, which contains graphical representations of cellular processes, such as metabolism, membrane transport, signal transduction and cell cycle. The PATHWAY database is supplemented by a set of ortholog group tables for the information about conserved subpathways (pathway motifs), which are often encoded by positionally coupled genes on the chromosome and which are especially useful in predicting gene functions. A third database in KEGG is LIGAND for the information about chemical compounds, enzyme molecules and enzymatic reactions. KEGG provides Java graphics tools for browsing genome maps, comparing two genome maps and manipulating expression maps, as well as computational tools for sequence comparison, graph comparison and path computation. The KEGG databases are daily updated and made freely available (http://www.genome.ad.jp/kegg/ ).},
	number = {1},
	urldate = {2018-08-08},
	journal = {Nucleic Acids Res},
	author = {Kanehisa, Minoru and Goto, Susumu},
	month = jan,
	year = {2000},
	pmid = {10592173},
	pmcid = {PMC102409},
	pages = {27--30},
	file = {PubMed Central Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/G8KKWH3R/Kanehisa and Goto - 2000 - KEGG Kyoto Encyclopedia of Genes and Genomes.pdf:application/pdf}
}

@article{tibshirani_sparsity_2005,
	title = {Sparsity and smoothness via the fused lasso},
	volume = {67},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00490.x},
	doi = {10.1111/j.1467-9868.2005.00490.x},
	abstract = {Summary. The lasso penalizes a least squares regression by the sum of the absolute values (L1-norm) of the coefficients. The form of this penalty encourages sparse solutions (with many coefficients equal to 0). We propose the ‘fused lasso’, a generalization that is designed for problems with features that can be ordered in some meaningful way. The fused lasso penalizes the L1-norm of both the coefficients and their successive differences. Thus it encourages sparsity of the coefficients and also sparsity of their differences—i.e. local constancy of the coefficient profile. The fused lasso is especially useful when the number of features p is much greater than N, the sample size. The technique is also extended to the ‘hinge’ loss function that underlies the support vector classifier. We illustrate the methods on examples from protein mass spectroscopy and gene expression data.},
	language = {en},
	number = {1},
	urldate = {2018-08-08},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
	month = feb,
	year = {2005},
	keywords = {Fused lasso, Gene expression, Lasso, Least squares regression, Protein mass spectroscopy, Sparse solutions, Support vector classifier},
	pages = {91--108},
	file = {Full Text PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/JSKDZDH5/Tibshirani et al. - 2005 - Sparsity and smoothness via the fused lasso.pdf:application/pdf;Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/V9ZA54Q2/j.1467-9868.2005.00490.html:text/html}
}

@article{munch_adaptive_2018,
	title = {Adaptive group-regularized logistic elastic net regression},
	url = {http://arxiv.org/abs/1805.00389},
	abstract = {In high-dimensional data settings, additional information on the features is often available. Examples of such external information in omics research are: (a) p-values from a previous study, (b) a summary of prior information, and (c) omics annotation. The inclusion of this information in the analysis may enhance classification performance and feature selection, but is not straightforward in the standard regression setting. As a solution to this problem, we propose a group-regularized (logistic) elastic net regression method, where each penalty parameter corresponds to a group of features based on the external information. The method, termed gren, makes use of the Bayesian formulation of logistic elastic net regression to estimate both the model and penalty parameters in an approximate empirical-variational Bayes framework. Simulations and an application to a colon cancer microRNA study show that, if the partitioning of the features is informative, classification performance and feature selection are indeed enhanced.},
	urldate = {2018-08-08},
	journal = {arXiv:1805.00389 [stat]},
	author = {Münch, Magnus M. and Peeters, Carel F. W. and van der Vaart, Aad W. and van de Wiel, Mark A.},
	month = may,
	year = {2018},
	note = {arXiv: 1805.00389},
	keywords = {Statistics - Methodology},
	file = {arXiv\:1805.00389 PDF:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/BRSR36CJ/Münch et al. - 2018 - Adaptive group-regularized logistic elastic net re.pdf:application/pdf;arXiv.org Snapshot:/Users/magnusmunch/Library/Application Support/Zotero/Profiles/klfpkvnp.default/zotero/storage/5Z9KDUGJ/1805.html:text/html}
}